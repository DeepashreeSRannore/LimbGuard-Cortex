# LimbGuard-Cortex

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

AI-powered diabetic foot assessment platform combining **Vision Transformer (ViT)** for gangrene classification, **NLP-based health advice**, and **Retrieval-Augmented Generation (RAG)** for evidence-based medical guidance.

## ğŸš€ Quick Start

### Prerequisites
- **Backend**: Python 3.8+
- **Frontend**: Node.js 18+
- **Package Managers**: pip, npm

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/DeepashreeSRannore/LimbGuard-Cortex.git
cd LimbGuard-Cortex
```

2. **Set up the backend:**
```bash
cd backend
pip install -r requirements.txt
cd ..
```

3. **Set up the frontend:**
```bash
cd frontend
npm install
cd ..
```

### Running Locally

**Terminal 1 - Backend:**
```bash
uvicorn backend.main:app --reload --port 8000
```

**Terminal 2 - Frontend:**
```bash
cd frontend
npm start
```

Visit `http://localhost:3000` in your browser.

## ğŸ“ Repository Structure

```
LimbGuard-Cortex/
â”œâ”€â”€ backend/                      # FastAPI backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ classification/       # ViT-based classifier
â”‚   â”‚   â”œâ”€â”€ nlp/                  # Health advice generator
â”‚   â”‚   â”œâ”€â”€ rag/                  # RAG engine with FAISS
â”‚   â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â”‚   â”œâ”€â”€ train_classifier.py   # Training script
â”‚   â”‚   â””â”€â”€ app.py                # Streamlit UI (alternative)
â”‚   â”œâ”€â”€ tests/                    # Backend tests
â”‚   â”œâ”€â”€ main.py                   # FastAPI app entry point
â”‚   â”œâ”€â”€ requirements.txt          # Python dependencies
â”‚   â””â”€â”€ README.md                 # Backend documentation
â”œâ”€â”€ frontend/                     # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/           # React components
â”‚   â”‚   â””â”€â”€ services/             # API client
â”‚   â”œâ”€â”€ public/                   # Static assets
â”‚   â”œâ”€â”€ package.json              # Node.js dependencies
â”‚   â””â”€â”€ README.md                 # Frontend documentation
â”œâ”€â”€ Dataset/                      # Training images (not in git)
â”‚   â”œâ”€â”€ normal_feet_images/       # Healthy foot images
â”‚   â””â”€â”€ wound-segmentation/       # Wound/ulcer images
â”œâ”€â”€ knowledge_base/               # Medical reference documents for RAG
â”‚   â”œâ”€â”€ diabetic_foot_guidelines.txt
â”‚   â””â”€â”€ wound_assessment_reference.txt
â””â”€â”€ README.md                     # This file
```

## ğŸ¯ Features

### Backend (FastAPI + Python)
- **REST API** for image classification
- **Vision Transformer (ViT)** fine-tuned on diabetic foot images
- **NLP Advice Generator** providing context-aware health recommendations
- **RAG Engine** with FAISS for evidence-based medical guidance
- **Demo Mode** for testing without trained model
- **Streamlit UI** as alternative interface

### Frontend (React + TypeScript)
- **Modern Material-UI** design
- **Drag-and-drop** image upload
- **Camera capture** for real-time image capture
- **Real-time predictions** with health advice
- **Error handling** and demo mode support
- **Responsive design** for mobile and desktop

## ğŸ”§ Training the Model

### 1. Build the RAG Index

```bash
python -m backend.src.rag.engine
```

This indexes medical documents from `knowledge_base/` into a FAISS vector store.

### 2. Train the Classifier

```bash
python -m backend.src.train_classifier --epochs 10 --batch-size 16
```

The model expects images in:
- `Dataset/normal_feet_images/` - Normal foot images
- `Dataset/wound-segmentation/data/Medetec_foot_ulcer_224/` - Wound images

Training creates `checkpoints/vit_classifier.pt`.

## ğŸ§ª Testing

**Backend:**
```bash
cd backend
pytest tests/ -v
```

**Frontend:**
```bash
cd frontend
npm test
```

## ğŸŒ Deployment

### Backend Deployment (Render)

1. **Create a Web Service** on [Render](https://render.com)
2. Connect your GitHub repository
3. Configure:
   - **Root Directory**: `backend`
   - **Build Command**: `pip install -r requirements.txt`
   - **Start Command**: `uvicorn main:app --host 0.0.0.0 --port $PORT`
4. Add environment variable:
   - `FRONTEND_URL`: Your frontend URL (e.g., `https://limbguard.vercel.app`)

**Alternative: Deploy to Heroku, Google Cloud Run, or AWS**

See detailed instructions in [backend/README.md](backend/README.md).

### Frontend Deployment (Vercel)

1. **Install Vercel CLI:**
```bash
npm install -g vercel
```

2. **Deploy from frontend directory:**
```bash
cd frontend
vercel
```

3. **Set environment variable** in Vercel dashboard:
   - `REACT_APP_API_URL`: Your backend URL (e.g., `https://limbguard-api.onrender.com`)

4. **Production deployment:**
```bash
vercel --prod
```

**Alternative: Deploy to Netlify**

```bash
cd frontend
npm run build
# Drag the 'build' folder to Netlify or use Netlify CLI
```

Set environment variable in Netlify:
- `REACT_APP_API_URL`: Your backend URL

### Complete Deployment Checklist

- [ ] Backend deployed to Render/Heroku (get backend URL)
- [ ] Set `FRONTEND_URL` environment variable in backend
- [ ] Frontend deployed to Vercel/Netlify (get frontend URL)
- [ ] Set `REACT_APP_API_URL` environment variable in frontend
- [ ] Test the deployed app end-to-end
- [ ] (Optional) Train and upload model checkpoint to backend server
- [ ] (Optional) Build RAG index on backend server

## âš™ï¸ Environment Variables

### Backend
```bash
# Optional: Frontend URL for CORS (production only)
FRONTEND_URL=https://your-frontend-url.vercel.app
```

### Frontend
```bash
# Backend API URL
REACT_APP_API_URL=http://localhost:8000  # Development
REACT_APP_API_URL=https://your-backend-url.onrender.com  # Production
```

## ğŸ“Š API Endpoints

### `GET /`
Health check

### `GET /demo`
Check if running in demo mode

### `POST /predict`
Upload image for prediction

**Request:** `multipart/form-data` with image file

**Response:**
```json
{
  "success": true,
  "demo_mode": false,
  "classification": "grade_2",
  "display_name": "Grade 2",
  "advice": {
    "status": "Gangrene detected â€“ grade 2.",
    "urgency": "MODERATE",
    "recommended_action": "...",
    "home_care": "..."
  },
  "rag_guidance": "Based on clinical guidelines..."
}
```

Full API documentation: `http://localhost:8000/docs` (when backend is running)

## ğŸ¨ Classification Grades

The model classifies foot images into 5 categories:

- **Normal**: Healthy foot, no signs of gangrene
- **Grade 1**: Superficial ulcer
- **Grade 2**: Deep ulcer, may involve tendon/bone
- **Grade 3**: Deep ulcer with abscess or osteomyelitis
- **Grade 4**: Gangrene of forefoot or limited area

## ğŸ’¡ Demo Mode

If no trained model is available, the app runs in **demo mode**:
- Predictions are simulated based on filename patterns
- All features work for testing
- A banner indicates demo mode is active

**To exit demo mode:**
1. Train the classifier (see Training the Model)
2. Ensure `checkpoints/vit_classifier.pt` exists
3. Restart the backend server

## ğŸ” Troubleshooting

### Backend won't start
- Ensure Python 3.8+ is installed: `python --version`
- Install dependencies: `pip install -r backend/requirements.txt`
- Check port 8000 is not in use: `lsof -i :8000` (macOS/Linux) or `netstat -ano | findstr :8000` (Windows)

### Frontend won't start
- Ensure Node.js 18+ is installed: `node --version`
- Install dependencies: `npm install` in frontend directory
- Check port 3000 is not in use

### Frontend can't connect to backend
- Ensure backend is running on port 8000
- Check `REACT_APP_API_URL` in frontend/.env
- Verify CORS settings in backend/main.py
- Check browser console for errors

### Model training fails
- **Out of memory**: Reduce batch size (`--batch-size 8`)
- **No images found**: Ensure Dataset/ folder contains images
- **CUDA error**: Use CPU by setting `CUDA_VISIBLE_DEVICES=""`

### Camera not working
- **Permissions**: Allow camera access in browser
- **HTTPS required**: Camera works on localhost or HTTPS only
- **No camera**: Use file upload instead

## ğŸ¥ Medical Disclaimer

âš ï¸ **IMPORTANT**: This tool is for **educational and research purposes only**. It does not replace professional medical advice, diagnosis, or treatment. Always consult a qualified healthcare provider for medical decisions.

## ï¿½ï¿½ Technology Stack

**Backend:**
- FastAPI - Web framework
- PyTorch - Deep learning
- Transformers (Hugging Face) - ViT model
- FAISS - Vector search for RAG
- Sentence Transformers - Embeddings
- Streamlit - Alternative UI

**Frontend:**
- React 19 - UI framework
- TypeScript - Type safety
- Material-UI (MUI) - Component library
- Axios - HTTP client
- React Dropzone - File upload

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Dataset**: Medetec Wound Database & AZH Wound & Vascular Center
- **Models**: Google ViT, Hugging Face Transformers
- **Medical Guidelines**: Referenced in knowledge_base/

## ğŸ“ Support

For questions or issues:
- Open an issue on GitHub
- Check documentation in backend/README.md and frontend/README.md
- Review the troubleshooting section above

---

**Built with â¤ï¸ for diabetic foot care research and education**
